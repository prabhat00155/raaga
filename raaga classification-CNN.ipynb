{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurise_data(folder):\n",
    "    res = []\n",
    "    time_slice = 30\n",
    "    for genre in os.listdir(folder):\n",
    "        dir_path = os.path.join(folder, genre)\n",
    "        if os.path.isdir(dir_path):\n",
    "            for file in os.listdir(dir_path):\n",
    "                if '.mp3' in file:\n",
    "                    songname = os.path.join(dir_path, file)\n",
    "                    print(f'Featurising song: {songname}')\n",
    "                    duration = librosa.get_duration(filename=songname)\n",
    "                    samples = int(duration // time_slice)\n",
    "                    for s in range(2, samples):\n",
    "                        y, sr = librosa.load(songname, mono=True, offset=s*time_slice, duration=time_slice)\n",
    "                        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "                        #print(mfcc.shape)\n",
    "                        res.append(np.array([genre, mfcc]))\n",
    "    return pd.DataFrame(np.array(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurising song: ../songs/train/mohanam/02-enduku_bAga_teliyadu-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/01-ninnu_kOriyunnAnurA-VARNAM-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/04-rArA_rAjIva_lOcana_rAma-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/09-swagatham_krishna-mohanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/02-En_paLLI_koNDIrayya-mOhanam-aruNAcala_kavi.mp3\n",
      "Featurising song: ../songs/train/mohanam/04-pAhi_mAm_pArvati_paramEshvari-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/01-Maruvaka_daya_mOhananga_nApai-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/06-dhim_dhim_kitataka_dhimta-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/06-sadA_pAlaya_sArasAkSi-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/04-mayil_vAhanA_vaLLi-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/07_giridhara_gOpAla_mOhana_pApanAsam_shivan.mp3\n",
      "Featurising song: ../songs/train/mohanam/13-jaya_mangaLam_nitya-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/02-manamOhanA_mAnini_nIpai-VARNAM-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/01_ninnE_kOriyunnadi_mA-VARNAM_mOhanam_vINai_kuppiyer.mp3\n",
      "Featurising song: ../songs/train/mohanam/03-rAjagOpAlam_bhajEham-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/13-darishinchuTa_telisenurA-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/05-mATi_mATiki_delpavalEnA-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/01-gOpikAmanOharam-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/06-bhuvanatraya_sammOhanakara-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/02-nArAyaNa_divya-mOhanam-pApanAsam_sivan.mp3\n",
      "Featurising song: ../songs/train/mohanam/04-EdEdO_eNNI_alaindEn-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/03-paaripAhi_mAm_nruharE-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/03-kAdambari_priyAyai-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/04-nAgalingam_namAmi_satatam-mOhanam-m_dIkshitar.mp3\n",
      "Featurising song: ../songs/train/mohanam/06-Bhadra_kali_namostute-mohanam-muttiah_bhagavatar.mp3\n",
      "Featurising song: ../songs/train/mohanam/06_BHAVANUTHA_MOHANAM.mp3\n",
      "Featurising song: ../songs/train/mohanam/03-mOhanaM_tava_vapuh-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/03-dhayarAni-mohanam-thyAgarAjar.mp3\n",
      "Featurising song: ../songs/train/mohanam/02-rAmanait-taruvAi-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/04-KRTP_Aya_kalai_kella-MOhana-Adhi-Dr_MBK.mp3\n",
      "Featurising song: ../songs/train/mohanam/02-rAdhA_ramaNa-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/06-Saundarya_vellam_tanil-mohanam-papanasham_shivan.mp3\n",
      "Featurising song: ../songs/train/mohanam/06-taTAkam_onru-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/02-nAgalingam_satatam-mOhanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/07_Kaapaali_Mohanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/05_Nannu_Paalimpa_Mohanam.mp3\n",
      "Featurising song: ../songs/train/mohanam/03-narasimha_agaccha_parabrahma-mOhanam.mp3\n",
      "Featurising song: ../songs/train/hindolam/Balamuralikrishna - The Best Carnatic singer HindolamMalkauns.mp3\n",
      "Featurising song: ../songs/train/hindolam/03-gAna_rasikE_gAna_vErevaru-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/Sri Kunnakudi presents-Raghavaibhavam-Hindolam.mp3\n",
      "Featurising song: ../songs/train/hindolam/05-gOvardhana_girIsham-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/04abhayavarade.mp3\n",
      "Featurising song: ../songs/train/hindolam/04-mAnavakula_bhUSaNa-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/03-dhImnanA_ta_dhiranA-TILLANA-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/06-mOhana_rAmA_mukhajita-mOhanam.mp3\n",
      "Featurising song: ../songs/train/hindolam/Deva Devam Bhaje by MS Subbulakshmi.mp3\n",
      "Featurising song: ../songs/train/hindolam/04-cintayAmi_jagadambAm-hindOLam-jayacAmarAja_wodayAr.mp3\n",
      "Featurising song: ../songs/train/hindolam/04-padmanAbha_pAhi-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/02-imaya_malai_peTra-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/2-saraswati-hindolam.mp3\n",
      "Featurising song: ../songs/train/hindolam/nilavum vAnum - hindOlam - Adi - kalaivAni.mp3\n",
      "Featurising song: ../songs/train/hindolam/Sudha Ragunathan - Maamavathu - Hindolam - Aadhi - Mysore Vasudevacharya (part 12).mp3\n",
      "Featurising song: ../songs/train/hindolam/04-mAmavatu_shrI_sarasvati-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/Ananya Ashok 01 sAmaja vara gamanA hindOLam tyAgarAja.mp3\n",
      "Featurising song: ../songs/train/hindolam/02-nIrajAkSi_kAmAkSi-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/03-tirupparam_kunra-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/01-mAl_marugan_murugan-HindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/Sama Gana Lolane Hindolam Bombay Jayashree.mp3\n",
      "Featurising song: ../songs/train/hindolam/07-manasulOni_marmamulu-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/11-Nava_lavanya_rupadhye-hindolam-muttiah_bhagavatar.mp3\n",
      "Featurising song: ../songs/train/hindolam/06-sAmagAna_lOlanE-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/04-gOvardhana_girIsham-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/01-sAmi_ninnE_kOri_yunnAnu-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/01-Eka_radanam-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/03-rAmanukku_mannan-hindolam-arunAchala_kavirAyar.mp3\n",
      "Featurising song: ../songs/train/hindolam/Pacchai Ma Malai - Hindolam.mp3\n",
      "Featurising song: ../songs/train/hindolam/03-nambik_keTTavar-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/03-mATSi_mighunda-hindOLam.mp3\n",
      "Featurising song: ../songs/train/hindolam/08_RTP_Hindolam.mp3\n",
      "Featurising song: ../songs/test/mohanam/01-rAmA_ninnu_nammina_vAramu-mOhanam.mp3\n",
      "Featurising song: ../songs/test/mohanam/21-mOhana_rAmA_mukhajita-mOhanam.mp3\n",
      "Featurising song: ../songs/test/mohanam/15._Ragam_Tanam___Mohanam.mp3\n",
      "Featurising song: ../songs/test/mohanam/15_Etarincha_mohanam_tyAgarAja.mp3\n",
      "Featurising song: ../songs/test/mohanam/014-sannutinceta-mOhanam.mp3\n",
      "Featurising song: ../songs/test/mohanam/13-thillAna-mOhana-Adhi-muththayya_bhAgavathar.mp3\n",
      "Featurising song: ../songs/test/mohanam/14-darishinchuTa_telisenurA-mOhanam.mp3\n",
      "Featurising song: ../songs/test/hindolam/15-mA_ramaNan_uma_ramaNan-hindOLam.mp3\n",
      "Featurising song: ../songs/test/hindolam/Preethi Kamath sings Raag Hindolam.mp3\n",
      "Featurising song: ../songs/test/hindolam/01-sakala_kalA_vANi-hindOLam.mp3\n",
      "Featurising song: ../songs/test/hindolam/04-shyAma_kalEbaram-hindOLam.mp3\n",
      "Featurising song: ../songs/test/hindolam/06-sAmaja_vara_gamanA_sAdhu-hindOLam.mp3\n",
      "Featurising song: ../songs/test/hindolam/gOvardhana girIsham-hindOLam - Muthuswamy Dikshithar - Trichur Brothers.mp3\n"
     ]
    }
   ],
   "source": [
    "train = featurise_data('../songs/train/')\n",
    "test = featurise_data('../songs/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mohanam</td>\n",
       "      <td>[[-134.61331, -139.08217, -146.79865, -147.290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohanam</td>\n",
       "      <td>[[-117.09872, -112.08309, -120.157104, -133.98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mohanam</td>\n",
       "      <td>[[-119.64694, -138.22232, -177.64699, -209.485...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mohanam</td>\n",
       "      <td>[[-134.68448, -157.24037, -186.11882, -186.297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mohanam</td>\n",
       "      <td>[[-76.544205, -66.21905, -73.61639, -77.88258,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1\n",
       "0  mohanam  [[-134.61331, -139.08217, -146.79865, -147.290...\n",
       "1  mohanam  [[-117.09872, -112.08309, -120.157104, -133.98...\n",
       "2  mohanam  [[-119.64694, -138.22232, -177.64699, -209.485...\n",
       "3  mohanam  [[-134.68448, -157.24037, -186.11882, -186.297...\n",
       "4  mohanam  [[-76.544205, -66.21905, -73.61639, -77.88258,..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1292)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1][23].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original, lab_train = train.iloc[:, 1:], train[0]\n",
    "X_test, lab_test = test.iloc[:, 1:], test[0]\n",
    "\n",
    "model_y = LabelEncoder().fit(lab_train)\n",
    "y_original = model_y.transform(lab_train)\n",
    "y_test = model_y.transform(lab_test)\n",
    "X_train, y_train = shuffle(X_original, y_original, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = 20\n",
    "window_length=1292\n",
    "channels = 1\n",
    "n_inputs = buckets * window_length * channels\n",
    "\n",
    "conv1_filters = 64\n",
    "conv1_ksize = 4\n",
    "conv1_stride = 1\n",
    "conv1_padding = 'SAME'\n",
    "\n",
    "conv2_filters = 64\n",
    "conv2_ksize = 4\n",
    "conv2_stride = 1\n",
    "conv2_padding = 'SAME'\n",
    "\n",
    "conv3_filters = 128\n",
    "conv3_ksize = 4\n",
    "conv3_stride = 1\n",
    "conv3_padding = 'SAME'\n",
    "\n",
    "conv4_filters = 64\n",
    "conv4_ksize = 3\n",
    "conv4_stride = 1\n",
    "conv4_padding = 'SAME'\n",
    "\n",
    "pool1_psize = (1, 4)\n",
    "pool1_stride = (1, 4)\n",
    "pool1_padding = 'VALID'\n",
    "\n",
    "pool2_psize = (1, 4)\n",
    "pool2_stride = (1, 4)\n",
    "pool2_padding = 'VALID'\n",
    "\n",
    "pool3_psize = (2, 4)\n",
    "pool3_stride = (2, 4)\n",
    "pool3_padding = 'VALID'\n",
    "\n",
    "pool4_psize = (2, 4)\n",
    "pool4_stride = (2, 4)\n",
    "pool4_padding = 'VALID'\n",
    "\n",
    "n_fc1 = 256\n",
    "n_fc2 = 128\n",
    "n_fc3 = 64\n",
    "n_outputs = 2\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0724 14:31:28.687176 4396492224 deprecation.py:323] From <ipython-input-27-f025b35086c4>:7: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0724 14:31:28.689610 4396492224 deprecation.py:506] From /Users/prroy/Documents/MachineLearning/speech/speech_env/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0724 14:31:28.886847 4396492224 deprecation.py:323] From <ipython-input-27-f025b35086c4>:8: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W0724 14:31:29.003696 4396492224 deprecation.py:323] From <ipython-input-27-f025b35086c4>:12: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0724 14:31:29.075376 4396492224 deprecation.py:323] From <ipython-input-27-f025b35086c4>:23: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, buckets, window_length), name='X')\n",
    "X_reshaped = tf.reshape(X, shape=(-1, buckets, window_length, channels))\n",
    "y = tf.placeholder(tf.int64, shape=(None), name='y')\n",
    "\n",
    "with tf.name_scope('cnn'):\n",
    "    conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_filters, kernel_size=conv1_ksize, strides=conv1_stride,\n",
    "                             padding=conv1_padding, activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(conv1, pool_size=pool1_psize, strides=pool1_stride, padding=pool1_padding)\n",
    "    conv2 = tf.layers.conv2d(pool1, filters=conv2_filters, kernel_size=conv2_ksize, strides=conv2_stride,\n",
    "                             padding=conv2_padding, activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, pool_size=pool2_psize, strides=pool2_stride, padding=pool2_padding)\n",
    "    drop1 = tf.layers.dropout(pool2, rate=0.2)\n",
    "    conv3 = tf.layers.conv2d(drop1, filters=conv3_filters, kernel_size=conv3_ksize, strides=conv3_stride,\n",
    "                             padding=conv3_padding, activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(conv3, pool_size=pool3_psize, strides=pool3_stride, padding=pool3_padding)\n",
    "    conv4 = tf.layers.conv2d(pool3, filters=conv4_filters, kernel_size=conv4_ksize, strides=conv4_stride,\n",
    "                             padding=conv4_padding, activation=tf.nn.relu)\n",
    "    pool4 = tf.layers.max_pooling2d(conv4, pool_size=pool4_psize, strides=pool4_stride, padding=pool4_padding)\n",
    "    drop2 = tf.layers.dropout(pool4, rate=0.2)\n",
    "    drop2_flat = tf.reshape(drop2, shape=(-1, 5 * 5 * conv4_filters))\n",
    "    \n",
    "with tf.name_scope('fc'):\n",
    "    dense1 = tf.layers.dense(drop2_flat, n_fc1, activation=tf.nn.relu, name='fc1')\n",
    "    dense2 = tf.layers.dense(dense1, n_fc2, activation=tf.nn.relu, name='fc2')\n",
    "    dense3 = tf.layers.dense(dense2, n_fc3, activation=tf.nn.relu, name='fc3')\n",
    "    drop3 = tf.layers.dropout(dense3, rate=0.5)\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    logits = tf.layers.dense(drop3, n_outputs, name='output')\n",
    "    y_prob = tf.nn.softmax(logits, name='y_prob')\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(starting_index, batch_size):\n",
    "    return (X_train_final[starting_index: min(starting_index + batch_size, len(X_train_final))],\n",
    "            y_train[starting_index: min(starting_index + batch_size, len(y_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = np.array(list(map(lambda x: x, X_train[1])))\n",
    "X_test_final = np.array(list(map(lambda x: x, X_test[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, training accuracy: 0.4854312241077423\n",
      "epoch: 1, training accuracy: 0.6672494411468506\n",
      "epoch: 2, training accuracy: 0.693473219871521\n",
      "epoch: 3, training accuracy: 0.7604895234107971\n",
      "epoch: 4, training accuracy: 0.8525640964508057\n",
      "epoch: 5, training accuracy: 0.866550087928772\n",
      "epoch: 6, training accuracy: 0.8904429078102112\n",
      "epoch: 7, training accuracy: 0.8904429078102112\n",
      "epoch: 8, training accuracy: 0.9696969985961914\n",
      "epoch: 9, training accuracy: 0.9801864624023438\n",
      "epoch: 10, training accuracy: 0.9324009418487549\n",
      "epoch: 11, training accuracy: 0.9836829900741577\n",
      "epoch: 12, training accuracy: 0.9714452028274536\n",
      "epoch: 13, training accuracy: 0.8916084170341492\n",
      "epoch: 14, training accuracy: 0.939976692199707\n",
      "epoch: 15, training accuracy: 0.9790209531784058\n",
      "epoch: 16, training accuracy: 0.9912587404251099\n",
      "epoch: 17, training accuracy: 0.9737762212753296\n",
      "epoch: 18, training accuracy: 0.9900932312011719\n",
      "epoch: 19, training accuracy: 0.9807692170143127\n",
      "epoch: 20, training accuracy: 0.9947552680969238\n",
      "epoch: 21, training accuracy: 0.997668981552124\n",
      "epoch: 22, training accuracy: 1.0\n",
      "epoch: 23, training accuracy: 1.0\n",
      "epoch: 24, training accuracy: 1.0\n",
      "epoch: 25, training accuracy: 1.0\n",
      "epoch: 26, training accuracy: 1.0\n",
      "epoch: 27, training accuracy: 1.0\n",
      "epoch: 28, training accuracy: 1.0\n",
      "epoch: 29, training accuracy: 1.0\n",
      "epoch: 30, training accuracy: 1.0\n",
      "epoch: 31, training accuracy: 1.0\n",
      "epoch: 32, training accuracy: 1.0\n",
      "epoch: 33, training accuracy: 1.0\n",
      "epoch: 34, training accuracy: 1.0\n",
      "epoch: 35, training accuracy: 1.0\n",
      "epoch: 36, training accuracy: 1.0\n",
      "epoch: 37, training accuracy: 1.0\n",
      "epoch: 38, training accuracy: 1.0\n",
      "epoch: 39, training accuracy: 1.0\n",
      "epoch: 40, training accuracy: 1.0\n",
      "epoch: 41, training accuracy: 1.0\n",
      "epoch: 42, training accuracy: 1.0\n",
      "epoch: 43, training accuracy: 1.0\n",
      "epoch: 44, training accuracy: 1.0\n",
      "epoch: 45, training accuracy: 1.0\n",
      "epoch: 46, training accuracy: 1.0\n",
      "epoch: 47, training accuracy: 1.0\n",
      "epoch: 48, training accuracy: 1.0\n",
      "epoch: 49, training accuracy: 1.0\n",
      "epoch: 50, training accuracy: 1.0\n",
      "epoch: 51, training accuracy: 1.0\n",
      "epoch: 52, training accuracy: 1.0\n",
      "epoch: 53, training accuracy: 1.0\n",
      "epoch: 54, training accuracy: 1.0\n",
      "epoch: 55, training accuracy: 1.0\n",
      "epoch: 56, training accuracy: 1.0\n",
      "epoch: 57, training accuracy: 1.0\n",
      "epoch: 58, training accuracy: 1.0\n",
      "epoch: 59, training accuracy: 1.0\n",
      "epoch: 60, training accuracy: 1.0\n",
      "epoch: 61, training accuracy: 1.0\n",
      "epoch: 62, training accuracy: 1.0\n",
      "epoch: 63, training accuracy: 1.0\n",
      "epoch: 64, training accuracy: 1.0\n",
      "epoch: 65, training accuracy: 1.0\n",
      "epoch: 66, training accuracy: 1.0\n",
      "epoch: 67, training accuracy: 1.0\n",
      "epoch: 68, training accuracy: 1.0\n",
      "epoch: 69, training accuracy: 1.0\n",
      "epoch: 70, training accuracy: 1.0\n",
      "epoch: 71, training accuracy: 1.0\n",
      "epoch: 72, training accuracy: 1.0\n",
      "epoch: 73, training accuracy: 1.0\n",
      "epoch: 74, training accuracy: 1.0\n",
      "epoch: 75, training accuracy: 1.0\n",
      "epoch: 76, training accuracy: 1.0\n",
      "epoch: 77, training accuracy: 1.0\n",
      "epoch: 78, training accuracy: 1.0\n",
      "epoch: 79, training accuracy: 1.0\n",
      "epoch: 80, training accuracy: 1.0\n",
      "epoch: 81, training accuracy: 1.0\n",
      "epoch: 82, training accuracy: 1.0\n",
      "epoch: 83, training accuracy: 1.0\n",
      "epoch: 84, training accuracy: 1.0\n",
      "epoch: 85, training accuracy: 1.0\n",
      "epoch: 86, training accuracy: 1.0\n",
      "epoch: 87, training accuracy: 1.0\n",
      "epoch: 88, training accuracy: 1.0\n",
      "epoch: 89, training accuracy: 1.0\n",
      "epoch: 90, training accuracy: 1.0\n",
      "epoch: 91, training accuracy: 1.0\n",
      "epoch: 92, training accuracy: 1.0\n",
      "epoch: 93, training accuracy: 1.0\n",
      "epoch: 94, training accuracy: 1.0\n",
      "epoch: 95, training accuracy: 1.0\n",
      "epoch: 96, training accuracy: 1.0\n",
      "epoch: 97, training accuracy: 1.0\n",
      "epoch: 98, training accuracy: 1.0\n",
      "epoch: 99, training accuracy: 1.0\n",
      "Test set accuracy : 0.565040647983551\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 100\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(math.ceil(len(X_train_final) / batch_size)):\n",
    "            X_batch, y_batch = get_next_batch(iteration * batch_size, batch_size)\n",
    "            #print(X_batch)\n",
    "            sess.run(training_op, feed_dict = {X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_train_final, y: y_train})\n",
    "        #acc_val = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print('epoch: {}, training accuracy: {}'.format(epoch, acc_train))\n",
    "    print('Test set accuracy : {}'.format(accuracy.eval(feed_dict={X: X_test_final, y: y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6707317073170732"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([('scaler', StandardScaler()),\n",
    "                  ('gb', GradientBoostingClassifier(learning_rate=0.05, n_estimators=200, random_state=42))])\n",
    "model.fit(X_train, y_train)\n",
    "np.mean(model.predict(X_test) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_raaga(model, songname):\n",
    "    time_slice = 30           \n",
    "    duration = librosa.get_duration(filename=songname)\n",
    "    samples = int(duration // time_slice)\n",
    "    preds = []\n",
    "    for s in range(2, samples):\n",
    "        y, sr = librosa.load(songname, mono=True, offset=s*time_slice, duration=time_slice)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        X_features = np.median(mfcc, axis=1)\n",
    "        preds.append(model.predict([X_features])[0])\n",
    "    return np.argmax(np.bincount(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predictions(model, folder):\n",
    "    for genre in os.listdir(folder):\n",
    "        dir_path = os.path.join(folder, genre)\n",
    "        if os.path.isdir(dir_path):\n",
    "            for file in os.listdir(dir_path):\n",
    "                if '.mp3' in file:\n",
    "                    pred = predict_raaga(model, os.path.join(dir_path, file))\n",
    "                    print(f'Actual = {genre}, Prediction = {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual = mohanam, Prediction = 1\n",
      "Actual = mohanam, Prediction = 0\n",
      "Actual = mohanam, Prediction = 1\n",
      "Actual = mohanam, Prediction = 1\n",
      "Actual = mohanam, Prediction = 1\n",
      "Actual = mohanam, Prediction = 1\n",
      "Actual = mohanam, Prediction = 1\n",
      "Actual = hindolam, Prediction = 1\n",
      "Actual = hindolam, Prediction = 0\n",
      "Actual = hindolam, Prediction = 1\n",
      "Actual = hindolam, Prediction = 0\n",
      "Actual = hindolam, Prediction = 1\n",
      "Actual = hindolam, Prediction = 1\n"
     ]
    }
   ],
   "source": [
    "run_predictions(model, '../songs/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('raaga_model_1.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raaga_model_1.pkl', 'rb') as f:\n",
    "    p_mod = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
